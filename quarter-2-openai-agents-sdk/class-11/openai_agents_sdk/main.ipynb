{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1d027af",
   "metadata": {},
   "source": [
    "# ü§ñ OpenAI Agents SDK ‚Äì Class 11 (1st November 2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9570f077",
   "metadata": {},
   "source": [
    "### üì¶ Install `openai-agents` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f6a8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU openai-agents python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c97afba",
   "metadata": {},
   "source": [
    "### Make Jupyter Notebook capable of running asynchronous functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "602e73ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab3ae05",
   "metadata": {},
   "source": [
    "### üåê Global Configurations for Connecting to Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1080880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI\n",
    "from agents import set_default_openai_api, set_default_openai_client, set_tracing_disabled\n",
    "\n",
    "# Setup for Api Keys\n",
    "load_dotenv()\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "# Which LLM Service?\n",
    "external_client = AsyncOpenAI(\n",
    "    api_key=gemini_api_key,\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
    ")\n",
    "\n",
    "# Global Setup for Connecting to Gemini\n",
    "set_tracing_disabled(disabled=True)\n",
    "set_default_openai_client(client=external_client)\n",
    "set_default_openai_api(\"chat_completions\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd2d38a",
   "metadata": {},
   "source": [
    "## Response Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6734d013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'What 2 + 2?', 'role': 'user'},\n",
       " {'arguments': '{}',\n",
       "  'call_id': 'function-call-947881898374134618',\n",
       "  'name': 'transfer_to_maths_agent',\n",
       "  'type': 'function_call',\n",
       "  'id': '__fake_id__'},\n",
       " {'call_id': 'function-call-947881898374134618',\n",
       "  'output': '{\"assistant\": \"Maths Agent\"}',\n",
       "  'type': 'function_call_output'},\n",
       " {'id': '__fake_id__',\n",
       "  'content': [{'annotations': [], 'text': '2 + 2 = 4', 'type': 'output_text'}],\n",
       "  'role': 'assistant',\n",
       "  'status': 'completed',\n",
       "  'type': 'message'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'content': 'What 2 + 2?', 'role': 'user'},\n",
       " {'arguments': '{}',\n",
       "  'call_id': 'function-call-947881898374134618',\n",
       "  'name': 'transfer_to_maths_agent',\n",
       "  'type': 'function_call',\n",
       "  'id': '__fake_id__'},\n",
       " {'call_id': 'function-call-947881898374134618',\n",
       "  'output': '{\"assistant\": \"Maths Agent\"}',\n",
       "  'type': 'function_call_output'},\n",
       " {'id': '__fake_id__',\n",
       "  'content': [{'annotations': [], 'text': '2 + 2 = 4', 'type': 'output_text'}],\n",
       "  'role': 'assistant',\n",
       "  'status': 'completed',\n",
       "  'type': 'message'},\n",
       " {'role': 'user', 'content': 'Now add 15 in it.'},\n",
       " {'id': '__fake_id__',\n",
       "  'content': [{'annotations': [],\n",
       "    'text': '2 + 2 + 15 = 19',\n",
       "    'type': 'output_text'}],\n",
       "  'role': 'assistant',\n",
       "  'status': 'completed',\n",
       "  'type': 'message'}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from agents import Agent, Runner\n",
    "\n",
    "maths_agent = Agent(\n",
    "    name=\"Maths Agent\",\n",
    "    model=\"gemini-2.5-flash\",\n",
    ")\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Traige Agent\",\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    handoffs=[maths_agent],\n",
    ")\n",
    "\n",
    "result = Runner.run_sync(\n",
    "    starting_agent=agent,\n",
    "    input=\"What 2 + 2?\"\n",
    ")\n",
    "\n",
    "display(result.to_input_list())\n",
    "\n",
    "new_input = result.to_input_list() + [{\"role\": \"user\", \"content\": \"Now add 15 in it.\"}]\n",
    "\n",
    "result2 = Runner.run_sync(\n",
    "    starting_agent=agent,\n",
    "    input=new_input\n",
    ")\n",
    "\n",
    "display(result2.to_input_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bdbc43",
   "metadata": {},
   "source": [
    "## Max turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12b0a87",
   "metadata": {},
   "outputs": [
    {
     "ename": "MaxTurnsExceeded",
     "evalue": "Max turns (1) exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMaxTurnsExceeded\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m a + b\n\u001b[32m      8\u001b[39m agent = Agent(\n\u001b[32m      9\u001b[39m     name=\u001b[33m\"\u001b[39m\u001b[33mTraige Agent\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     10\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mgemini-2.5-flash\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     11\u001b[39m     tools=[add_two_numbers],\n\u001b[32m     12\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m result = \u001b[43mRunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_sync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstarting_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat 2 + 2?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_turns\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     18\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(result.final_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dell\\Desktop\\piaic\\quarter-2-openai-agents-sdk\\class-11\\openai_agents_sdk\\.venv\\Lib\\site-packages\\agents\\run.py:416\u001b[39m, in \u001b[36mRunner.run_sync\u001b[39m\u001b[34m(cls, starting_agent, input, context, max_turns, hooks, run_config, previous_response_id, conversation_id, session)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    370\u001b[39m \u001b[33;03mRun a workflow synchronously, starting at the given agent.\u001b[39;00m\n\u001b[32m    371\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    412\u001b[39m \u001b[33;03m    type of the output.\u001b[39;00m\n\u001b[32m    413\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    415\u001b[39m runner = DEFAULT_AGENT_RUNNER\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_sync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstarting_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    418\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    419\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_turns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_turns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprevious_response_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprevious_response_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconversation_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconversation_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m    \u001b[49m\u001b[43msession\u001b[49m\u001b[43m=\u001b[49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dell\\Desktop\\piaic\\quarter-2-openai-agents-sdk\\class-11\\openai_agents_sdk\\.venv\\Lib\\site-packages\\agents\\run.py:723\u001b[39m, in \u001b[36mAgentRunner.run_sync\u001b[39m\u001b[34m(self, starting_agent, input, **kwargs)\u001b[39m\n\u001b[32m    720\u001b[39m conversation_id = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mconversation_id\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    721\u001b[39m session = kwargs.get(\u001b[33m\"\u001b[39m\u001b[33msession\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m723\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_event_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    724\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    725\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstarting_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    726\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    727\u001b[39m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[43m=\u001b[49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    728\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_turns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_turns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    732\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprevious_response_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprevious_response_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconversation_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconversation_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dell\\Desktop\\piaic\\quarter-2-openai-agents-sdk\\class-11\\openai_agents_sdk\\.venv\\Lib\\site-packages\\nest_asyncio.py:98\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     97\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.9-windows-x86_64-none\\Lib\\asyncio\\futures.py:202\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\uv\\python\\cpython-3.12.9-windows-x86_64-none\\Lib\\asyncio\\tasks.py:314\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    311\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    312\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    313\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    316\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dell\\Desktop\\piaic\\quarter-2-openai-agents-sdk\\class-11\\openai_agents_sdk\\.venv\\Lib\\site-packages\\agents\\run.py:595\u001b[39m, in \u001b[36mAgentRunner.run\u001b[39m\u001b[34m(self, starting_agent, input, **kwargs)\u001b[39m\n\u001b[32m    587\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m current_turn > max_turns:\n\u001b[32m    588\u001b[39m     _error_tracing.attach_error_to_span(\n\u001b[32m    589\u001b[39m         current_span,\n\u001b[32m    590\u001b[39m         SpanError(\n\u001b[32m   (...)\u001b[39m\u001b[32m    593\u001b[39m         ),\n\u001b[32m    594\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m595\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MaxTurnsExceeded(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMax turns (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_turns\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) exceeded\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    597\u001b[39m logger.debug(\n\u001b[32m    598\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRunning agent \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_agent.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (turn \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_turn\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    599\u001b[39m )\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m current_turn == \u001b[32m1\u001b[39m:\n",
      "\u001b[31mMaxTurnsExceeded\u001b[39m: Max turns (1) exceeded"
     ]
    }
   ],
   "source": [
    "from agents import Agent, Runner, function_tool\n",
    "\n",
    "@function_tool\n",
    "def add_two_numbers(a: int, b: int):\n",
    "    return a + b\n",
    "\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Traige Agent\",\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    tools=[add_two_numbers],\n",
    ")\n",
    "\n",
    "result = Runner.run_sync(\n",
    "    starting_agent=agent,\n",
    "    input=\"What 2 + 2?\",\n",
    "    max_turns=1\n",
    ")\n",
    "\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e068551",
   "metadata": {},
   "source": [
    "## Model Settings\n",
    "### Tool Choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa9eeacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add_two_numbers function called with arguments: a=1, b=2\n",
      "I can answer questions using numbers. I cannot answer general knowledge questions. Would you like me to help with a math question?\n"
     ]
    }
   ],
   "source": [
    "from agents import Agent, Runner, ModelSettings\n",
    "\n",
    "\n",
    "@function_tool\n",
    "def add_two_numbers(a: int, b: int):\n",
    "    print(f\"add_two_numbers function called with arguments: a={a}, b={b}\")\n",
    "    return a + b\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Assistant\",\n",
    "    instructions=\"You are a helpful assistant. Answer user's query\",\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    tools=[add_two_numbers],\n",
    "    model_settings=ModelSettings(\n",
    "        tool_choice=\"required\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "result = Runner.run_sync(\n",
    "    starting_agent=agent,\n",
    "    input=\"Who is founder of pakistan\",\n",
    ")\n",
    "\n",
    "\n",
    "print(result.final_output)\n",
    "# See tracing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool use behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb7f23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6\n"
     ]
    }
   ],
   "source": [
    "from agents import Agent, Runner\n",
    "\n",
    "\n",
    "@function_tool\n",
    "def add_two_numbers(a: int, b: int):\n",
    "    return a + b - 10\n",
    "\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Traige Agent\",\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    tools=[add_two_numbers],\n",
    "    tool_use_behavior=\"stop_on_first_tool\",\n",
    ")\n",
    "\n",
    "result = Runner.run_sync(\n",
    "    starting_agent=agent,\n",
    "    input=\"What 2 + 2?\",\n",
    ")\n",
    "\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fde22be",
   "metadata": {},
   "source": [
    "### Max tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2791fda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from agents import Agent, Runner, ModelSettings\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Assistant\",\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    model_settings=ModelSettings(max_tokens=100)\n",
    ")\n",
    "\n",
    "result = Runner.run_sync(\n",
    "    starting_agent=agent,\n",
    "    input=\"Write blog on AI in 500 words.\",\n",
    ")\n",
    "\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a85525",
   "metadata": {},
   "source": [
    "### Parallel Tool Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2911e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import Agent, Runner, ModelSettings\n",
    "import time\n",
    "\n",
    "\n",
    "@function_tool\n",
    "def add_two_numbers(a: int, b: int):\n",
    "    print(\"add_two_numbers function called\")\n",
    "    time.sleep(3) # Pause for 3 seconds\n",
    "    print(\"add_two_numbers function end\")\n",
    "\n",
    "    return a + b\n",
    "\n",
    "@function_tool\n",
    "def multiply_two_numbers(a: int, b: int):\n",
    "    print(\"multiply_two_numbers function called\")\n",
    "    time.sleep(2) # Pause for 2 seconds\n",
    "    print(\"multiply_two_numbers function end\")\n",
    "\n",
    "    return a * b\n",
    "\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"My Agent\",\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    tools=[add_two_numbers, multiply_two_numbers],\n",
    "    model_settings=ModelSettings(parallel_tool_calls=True),  # use gpt model here, or any model that supports parallel tool calls,\n",
    ")\n",
    "\n",
    "result = Runner.run_sync(\n",
    "    starting_agent=agent,\n",
    "    input=\"What 2 + 2 and 6 times 7?\",\n",
    ")\n",
    "\n",
    "print(result.final_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "### LLM Output Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d708140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are 5 jokes for you!\n",
      "\n",
      "1.  Why don't scientists trust atoms?\n",
      "    *   Because they make up *everything*!\n",
      "\n",
      "2.  What do you call a boomerang that won't come back?\n",
      "    *   A stick.\n",
      "\n",
      "3.  Knock, knock.\n",
      "    *   Who's there?\n",
      "    *   Interrupting cow.\n",
      "    *   Interrupting co‚Äî\n",
      "    *   MOOOOOOO!\n",
      "\n",
      "4.  I told my wife she should embrace her mistakes.\n",
      "    *   She gave me a hug.\n",
      "\n",
      "5.  Why did the scarecrow win an award?\n",
      "    *   Because he was outstanding in his field!"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from agents import Agent, Runner\n",
    "from openai.types.responses import ResponseTextDeltaEvent\n",
    "\n",
    "agent = Agent(name=\"Joker\", model=\"gemini-2.5-flash\")\n",
    "\n",
    "async def main():\n",
    "    result = Runner.run_streamed(agent, input=\"Please tell me 5 jokes.\")\n",
    "\n",
    "    async for event in result.stream_events():\n",
    "        if event.type == \"raw_response_event\" and isinstance(event.data, ResponseTextDeltaEvent):\n",
    "            print(event.data.delta, end=\"\", flush=True)\n",
    "\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bec5d3b",
   "metadata": {},
   "source": [
    "### Agent Loop Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04fd9bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Run starting ===\n",
      "Agent updated: Joker\n",
      "-- Message output:\n",
      " Here are 5 jokes for you!\n",
      "\n",
      "1.  **Why don't scientists trust atoms?**\n",
      "    Because they make up everything!\n",
      "\n",
      "2.  **What do you call a fake noodle?**\n",
      "    An impasta!\n",
      "\n",
      "3.  **Why did the scarecrow win an award?**\n",
      "    Because he was outstanding in his field!\n",
      "\n",
      "4.  **Knock, knock.**\n",
      "    *Who's there?*\n",
      "    Lettuce.\n",
      "    *Lettuce who?*\n",
      "    Lettuce in, it's cold out here!\n",
      "\n",
      "5.  **What's an astronaut's favorite part of a computer?**\n",
      "    The space bar!\n",
      "=== Run complete ===\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from agents import Agent, ItemHelpers, Runner\n",
    "\n",
    "agent = Agent(name=\"Joker\", model=\"gemini-2.5-flash\")\n",
    "\n",
    "async def main():\n",
    "    result = Runner.run_streamed(agent, input=\"Please tell me 5 jokes.\")\n",
    "\n",
    "    print(\"=== Run starting ===\")\n",
    "    async for event in result.stream_events():\n",
    "        # We'll ignore the raw responses event deltas\n",
    "        if event.type == \"raw_response_event\":\n",
    "            continue\n",
    "\n",
    "        elif event.type == \"agent_updated_stream_event\":\n",
    "            print(f\"Agent updated: {event.new_agent.name}\")\n",
    "            continue\n",
    "\n",
    "        elif event.type == \"run_item_stream_event\":\n",
    "            if event.item.type == \"tool_call_item\":\n",
    "                print(\"-- Tool was called\")\n",
    "            elif event.item.type == \"tool_call_output_item\":\n",
    "                print(f\"-- Tool output: {event.item.output}\")\n",
    "            elif event.item.type == \"message_output_item\":\n",
    "                print(f\"-- Message output:\\n {ItemHelpers.text_message_output(event.item)}\")\n",
    "            else:\n",
    "                pass  # Ignore other event types\n",
    "\n",
    "    print(\"=== Run complete ===\")\n",
    "\n",
    "\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88720d23",
   "metadata": {},
   "source": [
    "## Error in Tool (Agent Loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d28a2ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, I wasn't able to get the answer to your question. Please try again.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from agents import Agent, Runner, function_tool\n",
    "\n",
    "@function_tool\n",
    "def multiply(a: int, b: int):\n",
    "    return a / 0\n",
    "\n",
    "agent = Agent(name=\"Assistant\", tools=[multiply], model=\"gemini-2.5-flash\")\n",
    "result = Runner.run_sync(agent, input=\"What is 7 by 7?\")\n",
    "\n",
    "print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e59efb",
   "metadata": {},
   "source": [
    "## Clone Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7291da7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Agent Tools:  [FunctionTool(name='calculate_area', description='', params_json_schema={'properties': {'length': {'title': 'Length', 'type': 'number'}, 'width': {'title': 'Width', 'type': 'number'}}, 'required': ['length', 'width'], 'title': 'calculate_area_args', 'type': 'object', 'additionalProperties': False}, on_invoke_tool=<function function_tool.<locals>._create_function_tool.<locals>._on_invoke_tool at 0x000001DC6981A840>, strict_json_schema=True, is_enabled=True, tool_input_guardrails=None, tool_output_guardrails=None)]\n",
      "Weather Agent Tools:  ['calculate_area', 'get_weather']\n",
      "Math Agent Tools:  ['calculate_area']\n"
     ]
    }
   ],
   "source": [
    "from agents import function_tool\n",
    "\n",
    "@function_tool\n",
    "def calculate_area(length: float, width: float) -> str:\n",
    "    return f\"Area = {length * width} square units\"\n",
    "\n",
    "@function_tool\n",
    "def get_weather(city: str) -> str:\n",
    "    return f\"Weather in {city}: Sunny, 72¬∞F\"\n",
    "\n",
    "# Base agent with one tool\n",
    "base_agent = Agent(\n",
    "    name=\"BaseAssistant\",\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    tools=[calculate_area],\n",
    "    instructions=\"You are a helpful assistant.\",\n",
    ")\n",
    "\n",
    "# Clone with additional tool\n",
    "weather_agent = base_agent.clone(\n",
    "    name=\"WeatherAssistant\",\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    tools=[calculate_area, get_weather],  # New tools list\n",
    "    instructions=\"You are a weather and math assistant.\",\n",
    ")\n",
    "\n",
    "# Clone with same tools\n",
    "math_agent = base_agent.clone(\n",
    "    name=\"MathAssistant\",\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    instructions=\"You are a math specialist.\",\n",
    ")\n",
    "\n",
    "print(\"Base Agent Tools: \", base_agent.tools)\n",
    "print(\"Weather Agent Tools: \", [tool.name for tool in weather_agent.tools])\n",
    "print(\"Math Agent Tools: \", [tool.name for tool in math_agent.tools])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ba44fb",
   "metadata": {},
   "source": [
    "## Advance Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e00b20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d11466d0",
   "metadata": {},
   "source": [
    "## Structure Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1a7357b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "location='Karachi' temperature_c=30.0 summary='Partly cloudy'\n",
      "Karachi\n",
      "30.0\n",
      "Partly cloudy\n"
     ]
    }
   ],
   "source": [
    "from agents import Agent, Runner\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class WeatherAnswer(BaseModel):\n",
    "    location: str\n",
    "    temperature_c: float\n",
    "    summary: str\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"Assistant\",\n",
    "    output_type=WeatherAnswer,\n",
    "    model=\"gemini-2.5-flash\",\n",
    ")\n",
    "\n",
    "result = Runner.run_sync(agent, \"What's the weather in Karachi?\")\n",
    "\n",
    "# Perfect! Now you get structured data:\n",
    "print(result.final_output)\n",
    "print(result.final_output.location)      # \"Karachi\"\n",
    "print(result.final_output.temperature_c) # 30.0\n",
    "print(result.final_output.summary)       # \"clear skies\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedcb107",
   "metadata": {},
   "source": [
    "## Lifecyles\n",
    "### Agent Hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "acad9bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import AgentHooks\n",
    "\n",
    "class TestAgHooks(AgentHooks):\n",
    "    def __init__(self, ag_display_name):\n",
    "        self.event_counter = 0\n",
    "        self.ag_display_name = ag_display_name\n",
    "\n",
    "    async def on_start(self, context, agent) -> None:\n",
    "        self.event_counter += 1\n",
    "        print(f\"### {self.ag_display_name} {self.event_counter}: Agent {agent.name} started.\")\n",
    "\n",
    "    async def on_end(self, context, agent, output) -> None:\n",
    "        self.event_counter += 1\n",
    "        print(f\"### {self.ag_display_name} {self.event_counter}: Agent {agent.name} ended. Output: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5166bc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from agents import AgentHooks, RunContextWrapper\n",
    "\n",
    "class TestAgHooks(AgentHooks):\n",
    "    def __init__(self, ag_display_name):\n",
    "        self.event_counter = 0\n",
    "        self.ag_display_name = ag_display_name\n",
    "\n",
    "    async def on_start(self, context: RunContextWrapper, agent: Agent) -> None:\n",
    "        self.event_counter += 1\n",
    "        print(f\"### {self.ag_display_name} {self.event_counter}: Agent {agent.name} started. Usage: {context.usage}\")\n",
    "\n",
    "    async def on_end(self, context: RunContextWrapper, agent: Agent, output: Any) -> None:\n",
    "        self.event_counter += 1\n",
    "        print(f\"### {self.ag_display_name} {self.event_counter}: Agent {agent.name} ended. Usage: {context.usage}, Output: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29f55f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### content_moderator 1: Agent Content Moderator Agent started. Usage: Usage(requests=0, input_tokens=0, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=0, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=0)\n",
      "### content_moderator 2: Agent Content Moderator Agent ended. Usage: Usage(requests=1, input_tokens=49, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=10, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=142), Output: This query asks about AI and needs an answer.\n",
      "This query asks about AI and needs an answer.\n",
      "--end--\n"
     ]
    }
   ],
   "source": [
    "start_agent = Agent(\n",
    "    name=\"Content Moderator Agent\",\n",
    "    instructions=\"You are content moderation agent. Watch social media content received and flag queries that need help or answer. We will answer anything about AI?\",\n",
    "    hooks=TestAgHooks(ag_display_name=\"content_moderator\"),\n",
    "    model=\"gemini-2.5-flash\"\n",
    ")\n",
    "\n",
    "async def main():\n",
    "  result = await Runner.run(\n",
    "      start_agent,\n",
    "      input=f\"<tweet>Will Agentic AI Die at end of 2025?.</tweet>\"\n",
    "  )\n",
    "\n",
    "  print(result.final_output)\n",
    "\n",
    "asyncio.run(main())\n",
    "print(\"--end--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36278e0d",
   "metadata": {},
   "source": [
    "## Runner Hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1909e72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåÖ SYSTEM: CustomerService is now working\n",
      "   Active agents so far: ['CustomerService']\n",
      "üìû SYSTEM: CustomerService is thinking...\n",
      "üß†‚ú® SYSTEM: CustomerService finished thinking\n",
      "‚úÖ SYSTEM: CustomerService completed their work\n",
      "üìä STATS: 1 agents used, 0 handoffs\n",
      "Could you please tell me more about the help you need with your account? For example, are you having a technical issue, or do you have a question about billing?\n"
     ]
    }
   ],
   "source": [
    "from agents import Agent, RunHooks, Runner\n",
    "\n",
    "# Create a system-wide monitoring class\n",
    "class SystemMonitor(RunHooks):\n",
    "    def __init__(self):\n",
    "        self.active_agents = []\n",
    "        self.tool_usage = {}\n",
    "        self.handoffs = 0\n",
    "\n",
    "    async def on_agent_start(self, context, agent):\n",
    "        self.active_agents.append(agent.name)\n",
    "        print(f\"üåÖ SYSTEM: {agent.name} is now working\")\n",
    "        print(f\"   Active agents so far: {self.active_agents}\")\n",
    "\n",
    "    async def on_llm_start(self, context, agent, system_prompt, input_items):\n",
    "        print(f\"üìû SYSTEM: {agent.name} is thinking...\")\n",
    "\n",
    "    async def on_llm_end(self, context, agent, response):\n",
    "        print(f\"üß†‚ú® SYSTEM: {agent.name} finished thinking\")\n",
    "\n",
    "    async def on_tool_start(self, context, agent, tool):\n",
    "        tool_name = tool.name\n",
    "        if tool_name not in self.tool_usage:\n",
    "            self.tool_usage[tool_name] = 0\n",
    "        self.tool_usage[tool_name] += 1\n",
    "        print(f\"üî® SYSTEM: {tool_name} used {self.tool_usage[tool_name]} times\")\n",
    "\n",
    "    async def on_tool_end(self, context, agent, tool, result):\n",
    "        print(f\"‚úÖüî® SYSTEM: {agent.name} finished using {tool.name}\")\n",
    "\n",
    "    async def on_handoff(self, context, from_agent, to_agent):\n",
    "        self.handoffs += 1\n",
    "        print(f\"üèÉ‚Äç‚ôÇÔ∏è‚û°Ô∏èüèÉ‚Äç‚ôÄÔ∏è HANDOFF #{self.handoffs}: {from_agent.name} ‚Üí {to_agent.name}\")\n",
    "\n",
    "    async def on_agent_end(self, context, agent, output):\n",
    "        print(f\"‚úÖ SYSTEM: {agent.name} completed their work\")\n",
    "        print(f\"üìä STATS: {len(self.active_agents)} agents used, {self.handoffs} handoffs\")\n",
    "\n",
    "\n",
    "# Create your agents\n",
    "tech_support = Agent(name=\"TechnicalSupport\", model=\"gemini-2.5-flash\")\n",
    "billing_manager = Agent(name=\"BillingManager\", model=\"gemini-2.5-flash\")\n",
    "customer_service = Agent(name=\"CustomerService\", model=\"gemini-2.5-flash\", handoffs=[tech_support, billing_manager])\n",
    "\n",
    "# Create the system monitor\n",
    "system_monitor = SystemMonitor()\n",
    "\n",
    "# Run with system-wide monitoring\n",
    "result = Runner.run_sync(\n",
    "    starting_agent=customer_service,\n",
    "    input=\"I need help with my account\",\n",
    "    hooks=system_monitor,  # This monitors EVERYTHING\n",
    ")\n",
    "\n",
    "print(result.final_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "context",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
